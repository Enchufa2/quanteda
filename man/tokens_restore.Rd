% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokens_restore.R
\name{tokens_restore}
\alias{tokens_restore}
\title{Restore special tokens}
\usage{
tokens_restore(x)
}
\arguments{
\item{x}{tokens object}
}
\description{
Compounds segments of tokens marked by special markers. The beginning and
the end of the segments should be marked by U+E001 and U+E002 respectively.
}
\examples{
txt <- c(d1 = "オリンピック延期決定！ #politics @abe #政治# #政治 #安部政権 @安部政権 ！")
txt <- stri_replace_all_regex(txt, "@[a-zA-Z0-9_]+|#[\\\\p{L}\\\\p{N}]+#?", "\uE001$0\uE002")
toks <- as.tokens(stri_split_boundaries(txt, type = "word"))
quanteda:::tokens_restore(toks)
}
